{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b10028b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd; pd.set_option('display.max_columns', None)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Инструкция по установке пакета: https://github.com/maks-sh/scikit-uplift\n",
    "# Ссылка на документацию: https://scikit-uplift.readthedocs.io/en/latest/\n",
    "from sklift.metrics import uplift_at_k\n",
    "from sklift.viz import plot_uplift_preds\n",
    "\n",
    "from sklift.models import SoloModel\n",
    "from sklift.models import ClassTransformation\n",
    "from sklift.models import TwoModels\n",
    "\n",
    "# sklift поддерживает любые модели, \n",
    "# которые удовлетворяют соглашениями scikit-learn\n",
    "# Для примера воспользуемся catboost\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4053ae7a",
   "metadata": {},
   "source": [
    "* channel - channels that the customer using, Phone/Web/Multichannel\n",
    "* is_referral - indicates if the customer was acquired from referral channel\n",
    "* zip_code - class of the zip code as Suburban/Urban/Rural\n",
    "* used_bogo - indicates if the customer used a buy one get one before\n",
    "* used_discount - indicates if the customer used a discount before\n",
    "* history - value of the historical purchases\n",
    "* recency - months since last purchase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baee51f",
   "metadata": {},
   "source": [
    "1. скачать набор данных маркетинговых кампаний отсюда https://www.kaggle.com/davinwijaya/customer-retention\n",
    "2. там поле conversion - это целевая переменная, а offer - коммуникация. Переименовать поля (conversion -> target, offer -> treatment) и привести поле treatment к бинарному виду (1 или 0, т.е было какое-то предложение или нет) - значение No Offer означает отсутствие коммуникации, а все остальные - наличие.\n",
    "3. сделать разбиение набора данных не тренировочную и тестовую выборки\n",
    "4. сделать feature engineering на ваше усмотрение (допускается свобода выбора методов)\n",
    "5. провести uplift-моделирование 3 способами: одна модель с признаком коммуникации (S learner), модель с трансформацией таргета (трансформация классов п. 2. 1) и вариант с двумя независимыми моделями\n",
    "6. в конце вывести единую таблицу сравнения метрик uplift@10%, uplift@20% этих 3 моделей\n",
    "7. построить модель UpliftTreeClassifier и попытаться описать словами полученное дерево\n",
    "8. (опционально) для модели S learner (модель с дополнительным признаком коммуникации) построить зависимость таргета (конверсии - поле conversion) от значения uplift: 1) сделать прогноз и получить uplift для тестовой выборки 2) отсортировать тестовую выборку по uplift по убыванию 3) разбить на децили (pandas qcut вам в помощь) 4) для каждого дециля посчитать среднюю conversion\n",
    "9. (опционально) построить модель UpliftRandomForestClassifier и попытаться описать словами полученное дерево"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72a8d2b",
   "metadata": {},
   "source": [
    "# 1-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ef8ae0d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recency</th>\n",
       "      <th>history</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>is_referral</th>\n",
       "      <th>channel</th>\n",
       "      <th>treatment</th>\n",
       "      <th>target</th>\n",
       "      <th>used_dics_or_bogo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>142.44</td>\n",
       "      <td>Surburban</td>\n",
       "      <td>0</td>\n",
       "      <td>Phone</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>329.08</td>\n",
       "      <td>Rural</td>\n",
       "      <td>1</td>\n",
       "      <td>Web</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>180.65</td>\n",
       "      <td>Surburban</td>\n",
       "      <td>1</td>\n",
       "      <td>Web</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recency  history   zip_code  is_referral channel  treatment  target  \\\n",
       "0       10   142.44  Surburban            0   Phone          1       0   \n",
       "1        6   329.08      Rural            1     Web          0       0   \n",
       "2        7   180.65  Surburban            1     Web          1       0   \n",
       "\n",
       "   used_dics_or_bogo  \n",
       "0                  1  \n",
       "1                  1  \n",
       "2                  1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data_for_task.csv')\n",
    "df.rename(columns={'conversion':'target', 'offer':'treatment'}, inplace=True)\n",
    "df['treatment'].replace({'Buy One Get One':1, 'Discount':1,'No Offer':0}, inplace=True)\n",
    "df['used_dics_or_bogo'] = np.where((df['used_discount'] == 1) | ( df['used_bogo'] == 1), 1,0)\n",
    "df.drop(columns=['used_discount', 'used_bogo'], inplace=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4540074d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1    66.709375\n",
       " 0    33.290625\n",
       " Name: treatment, dtype: float64,\n",
       " 0    85.321875\n",
       " 1    14.678125\n",
       " Name: target, dtype: float64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_f = ['zip_code', 'channel']\n",
    "models_results = {\n",
    "    'approach': [],\n",
    "    'uplift@10%': [], \n",
    "    'uplift@20%': []\n",
    "}\n",
    "df['treatment'].value_counts()*100/df.shape[0], df['target'].value_counts()*100/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4daa82ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['treatment', 'target'])\n",
    "W = df['treatment'] \n",
    "y = df['target']\n",
    "indices = df.index\n",
    "indices_learn, indices_valid = train_test_split(df.index, test_size=0.4, random_state=123, stratify=df['target'])\n",
    "# обучающий набор \n",
    "X_train = X.iloc[indices_learn]\n",
    "y_train = y.iloc[indices_learn]\n",
    "W_train = W.iloc[indices_learn]\n",
    "# валидационный набор\n",
    "X_test = X.iloc[indices_valid]\n",
    "y_test = y.iloc[indices_valid]\n",
    "W_test = W.iloc[indices_valid]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61027ee2",
   "metadata": {},
   "source": [
    "# 5-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "12db9db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uplift_data(model, X_train=X_train, y_train=y_train, W_train=W_train, y_test=y_test, W_test=W_test):\n",
    "    models_results = {\n",
    "    }\n",
    "    if model == TwoModels:\n",
    "        tm = TwoModels(\n",
    "        estimator_trmnt=CatBoostClassifier(iterations=20, thread_count=2, random_state=42, silent=True), \n",
    "        estimator_ctrl=CatBoostClassifier(iterations=20, thread_count=2, random_state=42, silent=True), \n",
    "            method='vanilla' )\n",
    "        tm = tm.fit( X_train, y_train, W_train,\n",
    "                    estimator_trmnt_fit_params={'cat_features': cat_f}, \n",
    "                    estimator_ctrl_fit_params={'cat_features': cat_f})\n",
    "\n",
    "        uplift_tm = tm.predict(X_test)\n",
    "\n",
    "        tm_score_1 = uplift_at_k(y_true=y_test, uplift=uplift_tm, treatment=W_test, strategy='by_group', k=0.1)\n",
    "        tm_score_2 = uplift_at_k(y_true=y_test, uplift=uplift_tm, treatment=W_test, strategy='by_group', k=0.2)\n",
    "        \n",
    "        models_results['approach']= model\n",
    "        models_results['uplift@10%']= tm_score_1\n",
    "        models_results['uplift@20%']= tm_score_2\n",
    "        \n",
    "    else:         \n",
    "        sm = model(CatBoostClassifier(iterations=20, thread_count=2, random_state=42, silent=True))\n",
    "        sm = sm.fit(X_train, y_train, W_train, estimator_fit_params={'cat_features': cat_f})\n",
    "        \n",
    "        uplift_sm = sm.predict(X_test)\n",
    "        \n",
    "        sm_score_1 = uplift_at_k(y_true=y_test, uplift=uplift_sm, treatment=W_test, strategy='by_group', k=0.1)\n",
    "        sm_score_2 = uplift_at_k(y_true=y_test, uplift=uplift_sm, treatment=W_test, strategy='by_group', k=0.2)\n",
    "        \n",
    "        models_results['approach']= model\n",
    "        models_results['uplift@10%']= sm_score_1\n",
    "        models_results['uplift@20%']= sm_score_2\n",
    "        \n",
    "    \n",
    "    return models_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "990a9896",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Solo</th>\n",
       "      <th>Class</th>\n",
       "      <th>TwoModels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>uplift@10%</th>\n",
       "      <td>0.058320</td>\n",
       "      <td>0.058372</td>\n",
       "      <td>0.053620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uplift@20%</th>\n",
       "      <td>0.060895</td>\n",
       "      <td>0.065608</td>\n",
       "      <td>0.050619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Solo     Class  TwoModels\n",
       "uplift@10%  0.058320  0.058372   0.053620\n",
       "uplift@20%  0.060895  0.065608   0.050619"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_results_solo = uplift_data(SoloModel, X_train=X_train, y_train=y_train, W_train=W_train, y_test=y_test, W_test=W_test)\n",
    "models_results_class = uplift_data(ClassTransformation, X_train=X_train, y_train=y_train, W_train=W_train, y_test=y_test, W_test=W_test)\n",
    "models_results_two = uplift_data(TwoModels, X_train=X_train, y_train=y_train, W_train=W_train, y_test=y_test, W_test=W_test)\n",
    "\n",
    "models_df = pd.DataFrame(list(models_results_solo.values())[1:], index=list(models_results_solo.keys())[1:], columns=['Solo'])\n",
    "models_df.insert(loc=len(models_df.columns), column='Class', value=list(models_results_class.values())[1:])\n",
    "models_df.insert(loc=len(models_df.columns), column='TwoModels', value=list(models_results_two.values())[1:])\n",
    "models_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eaba49",
   "metadata": {},
   "source": [
    "### UpliftTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc050a96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_18440\\3133210892.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  X_train_tree = pd.concat([X_train.drop('zip_code', 1),\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_18440\\3133210892.py:1: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.\n",
      "  X_train_tree = pd.concat([X_train.drop('zip_code', 1),\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_18440\\3133210892.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  X_train_tree = pd.concat([X_train_tree.drop('channel', 1),\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_18440\\3133210892.py:3: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.\n",
      "  X_train_tree = pd.concat([X_train_tree.drop('channel', 1),\n"
     ]
    }
   ],
   "source": [
    "X_train_tree = pd.concat([X_train.drop('zip_code', 1), \n",
    "                          pd.get_dummies(X_train['zip_code'], prefix='zip_code')], 1)\n",
    "X_train_tree = pd.concat([X_train_tree.drop('channel', 1), \n",
    "                          pd.get_dummies(X_train['channel'], prefix='channel')], 1)\n",
    "\n",
    "features = [col for col in X_train_tree]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ccbc2087",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'causalml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:2\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'causalml'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from IPython.display import Image\n",
    "from causalml.inference.tree import UpliftTreeClassifier, UpliftRandomForestClassifier\n",
    "from causalml.inference.tree import uplift_tree_string, uplift_tree_plot\n",
    "\n",
    "uplift_model = UpliftTreeClassifier(max_depth=8, min_samples_leaf=200, min_samples_treatment=50,\n",
    "                                    n_reg=100, evaluationFunction='KL', control_name='control')\n",
    "\n",
    "uplift_model.fit(X_train_tree.values,\n",
    "                 treatment=W_train.map({1: 'treatment1', 0: 'control'}).values,\n",
    "                 y=y_train)\n",
    "\n",
    "graph = uplift_tree_plot(uplift_model.fitted_uplift_tree, features)\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f1f3ab93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement causalml.inference.tree (from versions: none)\n",
      "ERROR: No matching distribution found for causalml.inference.tree\n"
     ]
    }
   ],
   "source": [
    "pip install causalml.inference.tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40586932",
   "metadata": {},
   "outputs": [],
   "source": [
    "git clone https://github.com/uber/causalml.git\n",
    "cd causalml\n",
    "pip install .\n",
    "python setup.py build_ext --inplace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243441fb",
   "metadata": {},
   "source": [
    "conda install -c conda-forge causalml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
